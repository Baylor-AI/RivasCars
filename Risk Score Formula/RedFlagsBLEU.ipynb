{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from ast import AsyncFunctionDef\n",
        "import spacy\n",
        "import numpy as np\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "\n",
        "#Load SpaCy English model with word embeddings\n",
        "try:\n",
        "    nlp = spacy.load('en_core_web_md')\n",
        "except OSError:\n",
        "    print('Downloading language model for the spaCy POS tagger\\n'\n",
        "        \"(don't worry, this will only happen once)\")\n",
        "    from spacy.cli import download\n",
        "    download('en_core_web_md')\n",
        "    nlp = spacy.load('en_core_web_md')\n",
        "\n",
        "#Function to compute sentence embedding\n",
        "def get_sentence_embedding(sentence):\n",
        "    doc = nlp(sentence)\n",
        "    if len(doc) == 0:  #Check if the doc is empty\n",
        "        return np.zeros((nlp.meta[\"vectors\"][\"width\"],))  #Return zero vector of proper length\n",
        "    embeddings = [token.vector for token in doc if token.has_vector]\n",
        "    if embeddings:\n",
        "        return np.mean(embeddings, axis=0)\n",
        "    else:\n",
        "        return np.zeros((nlp.meta[\"vectors\"][\"width\"],))  #Return zero vector if no token vectors found\n",
        "\n",
        "\n",
        "#Function to calculate cosine similarity\n",
        "def cosine_similarity(vec1, vec2):\n",
        "    if np.all(vec1 == 0) or np.all(vec2 == 0):\n",
        "        return 0.0\n",
        "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
        "\n",
        "#Define reference phrases and compute their embeddings\n",
        "reference_phrases = [\n",
        "    \"never opened\",\n",
        "    \"still sealed\",\n",
        "    \"must sell fast\",\n",
        "    \"contact me soon\",\n",
        "    \"offer won't last long\",\"cash only\", \"urgent sale\", \"need gone today\", \"no questions asked\",\n",
        "    \"quick transaction\", \"serious buyers only\", \"first come first serve\",\n",
        "    \"no returns\", \"price is firm\", \"selling cheap\", \"act fast\",\n",
        "    \"limited time offer\", \"confidential sale\", \"direct deal\", \"available immediately\",\"need to sell quickly\", \"looking for a quick sale\", \"urgent sale needed\",\n",
        "    \"unopened\", \"still in original packaging\", \"brand new condition\",\n",
        "    \"unbroken seal\", \"factory sealed\", \"not opened\"\n",
        "]\n",
        "reference_embeddings = [get_sentence_embedding(phrase) for phrase in reference_phrases]\n",
        "varied_references = [phrase.split() for phrase in reference_phrases]\n",
        "\n",
        "\n",
        "#Function to calculate semantic scores for a given sentence\n",
        "def get_semantic_score(sentence, reference_embeddings):\n",
        "    sentence_embedding = get_sentence_embedding(sentence)\n",
        "    scores = [cosine_similarity(sentence_embedding, ref_emb) for ref_emb in reference_embeddings]\n",
        "    return max(scores)  #return the highest similarity score\n",
        "\n",
        "#Calculate BLEU and Semantic scores\n",
        "weights_bleu = (1.0, 0.0, 0.0, 0.0)  #top performing weights from previous results\n",
        "smoother = SmoothingFunction().method1\n",
        "\n",
        "#Example input\n",
        "input_paragraph = \"\"\"\n",
        "I have a totally not stolen sealed camera that I need gone today. No questions asked about the sale. I guarantee you we can have the sale done with quickly. never opened, still sealed, not opened must sell fast.\n",
        "\"\"\"\n",
        "#Process input\n",
        "sentences = input_paragraph.strip().split('. ')\n",
        "bleu_scores = {}\n",
        "semantic_scores = {}\n",
        "\n",
        "DESCRIPTION_WEIGHT = 0.15\n",
        "#Function for computing the red-flag, description parameter of the risk score\n",
        "def calcDescriptionScore(redFlagWords):\n",
        "  descriptionScore = DESCRIPTION_WEIGHT * (1 - 1 / (redFlagWords + 1))\n",
        "  return descriptionScore\n",
        "\n",
        "#Sentences that exceed both thresholds contain red-flag words\n",
        "bleu_threshold = 0.65\n",
        "semantic_threshold = 0.7  #Example threshold for high semantic similarity\n",
        "red_flags_count = 0\n",
        "\n",
        "for sentence in sentences:\n",
        "    candidate = sentence.split()\n",
        "    #BLEU score\n",
        "    bleu_score = sentence_bleu(varied_references, candidate, weights=weights_bleu, smoothing_function=smoother)\n",
        "    bleu_scores[sentence] = bleu_score\n",
        "    #Semantic score\n",
        "    semantic_score = get_semantic_score(sentence, reference_embeddings)\n",
        "    semantic_scores[sentence] = semantic_score\n",
        "    #Count the number of sentences with red-flag words\n",
        "    if bleu_score >= bleu_threshold and semantic_score >= semantic_threshold:\n",
        "      red_flags_count = red_flags_count + 1\n",
        "\n",
        "#Weighted average of BLEU and Semantic scores (0.5 each)\n",
        "#Adjusted composite score calculation with new thresholds\n",
        "final_scores = {}\n",
        "for sentence in sentences:\n",
        "    adjusted_semantic_score = 1.0 if semantic_scores[sentence] > semantic_threshold else semantic_scores[sentence] / semantic_threshold\n",
        "    final_score = 0.6 * bleu_scores[sentence] + 0.4 * adjusted_semantic_score\n",
        "    final_scores[sentence] = final_score\n",
        "\n",
        "#Print the red-flags portion of the risk score\n",
        "red_flags_score = calcDescriptionScore(red_flags_count)\n",
        "print(\"Red Flags Risk Score:\", red_flags_score)\n",
        "\n",
        "final_scores\n",
        "#Print the results\n",
        "print(\"Results for each sentence:\")\n",
        "for sentence in sentences:\n",
        "    print(\"\\nSentence:\", sentence)\n",
        "    print(\"BLEU Score:\", bleu_scores[sentence])\n",
        "    print(\"Semantic Score:\", semantic_scores[sentence])\n",
        "    print(\"Composite Score (Weighted Average):\", final_scores[sentence])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQumC2ylRG69",
        "outputId": "e41d2fde-4e9c-4e5e-92d9-f0b235f4a06c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Red Flags Risk Score: 0.075\n",
            "Results for each sentence:\n",
            "\n",
            "Sentence: I have a totally not stolen sealed camera that I need gone today\n",
            "BLEU Score: 0.46153846153846156\n",
            "Semantic Score: 0.71726274\n",
            "Composite Score (Weighted Average): 0.676923076923077\n",
            "\n",
            "Sentence: No questions asked about the sale\n",
            "BLEU Score: 0.5\n",
            "Semantic Score: 0.69640267\n",
            "Composite Score (Weighted Average): 0.697944382258824\n",
            "\n",
            "Sentence: I guarantee you we can have the sale done with quickly\n",
            "BLEU Score: 0.18181818181818182\n",
            "Semantic Score: 0.7245456\n",
            "Composite Score (Weighted Average): 0.5090909090909091\n",
            "\n",
            "Sentence: never opened, still sealed, not opened must sell fast.\n",
            "BLEU Score: 0.6666666666666666\n",
            "Semantic Score: 0.8145937\n",
            "Composite Score (Weighted Average): 0.8\n"
          ]
        }
      ]
    }
  ]
}